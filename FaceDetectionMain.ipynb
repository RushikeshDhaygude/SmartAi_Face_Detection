{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44927b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [14/Apr/2023 22:28:04] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Apr/2023 22:28:20] \"POST / HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [14/Apr/2023 22:28:20] \"GET /room/ HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Logged in Successfully\n",
      "False Info\n",
      "Hello, logged in user!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Apr/2023 22:28:34] \"POST /room/ HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import time\n",
    "import winsound\n",
    "import base64\n",
    "import jwt\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "from flask import Flask,flash, render_template, request, redirect, url_for, jsonify, session\n",
    "\n",
    "Url= 'https://peach-violet-rhinoceros.glitch.me/api/v1'\n",
    "studentUrl=Url+\"/student/login\"\n",
    "joinSessionUrl=Url+\"/room/\"\n",
    "\n",
    "app = Flask(__name__, template_folder='templates', static_folder='static')\n",
    "\n",
    "app.secret_key = 'session'\n",
    "\n",
    "\n",
    "@app.route('/video_frames', methods=['POST'])\n",
    "def process_video_frames():\n",
    "    if request.method == 'POST':\n",
    "        print(\"HI\")\n",
    "    # Access the video frames in the request body and pass them to your attention level detection function\n",
    "        video_frames = request.data\n",
    "        run_eye_tracking(video_frames)\n",
    "#     return attention_level\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def login():\n",
    "    if request.method == 'POST':\n",
    "        username = request.form['username']\n",
    "        password = request.form['password'] \n",
    "        data = {'emailID': username, 'password': password}\n",
    "        response = requests.post(studentUrl, json=data)\n",
    "        if response.json()['success']:\n",
    "            # If the authentication was successful, store the token in the user's session\n",
    "            token = response.json()['data']['tokem']\n",
    "            session['user_data'] = {\n",
    "                'token': token,\n",
    "                'student': {\n",
    "                    '_id': response.json()['data']['student']['_id'],\n",
    "                    'emailID': response.json()['data']['student']['emailID'],\n",
    "                    'emailVerified': response.json()['data']['student']['emailVerified'] ,\n",
    "                }\n",
    "            }\n",
    "#             print(session)\n",
    "            print(\"User Logged in Successfully\")\n",
    "            return redirect(url_for('join_meeting'))\n",
    "        else:\n",
    "            session.clear()\n",
    "            print(\"Invalid Login Details\")       \n",
    "    else:\n",
    "        return render_template('login.html')\n",
    "    \n",
    "def getRoomId(roomId):\n",
    "    return roomId\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "#@app.route('/video_feed')\n",
    "#def video_feed():\n",
    "    #cap = cv2.VideoCapture(0)\n",
    "    #return Response(generate_frames(cap), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "\n",
    "#def generate_frames(cap):\n",
    "#     while True:\n",
    "#         success, frame = cap.read()\n",
    "#         if not success:\n",
    "#             break\n",
    "#         else:\n",
    "#             ret, buffer = cv2.imencode('.jpg', frame)\n",
    "#             frame = buffer.tobytes()\n",
    "#             yield (b'--frame\\r\\n'\n",
    "#                    b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "            \n",
    "            \n",
    "\n",
    "@app.route('/meeting_room', methods=['GET', 'POST'])\n",
    "def meeting_room():\n",
    "    if request.method == 'POST':\n",
    "        print(\"Hi\")\n",
    "        #run_eye_tracking()\n",
    "        return render_template('meeting_room.html')\n",
    "\n",
    "@app.route('/room/', methods=['GET', 'POST'])\n",
    "def join_meeting():\n",
    "    room_id=\"abcd\";\n",
    "    room=getRoomId(room_id)\n",
    "#     print(room)\n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        if \"user_data\" in session:\n",
    "            print(\"Hello, logged in user!\")\n",
    "        else:\n",
    "            print(\"Please log in\")\n",
    "            return render_template('login.html')\n",
    "            \n",
    "        session_id=room\n",
    "        roomlink=joinSessionUrl+session_id\n",
    "        user_data = session['user_data']\n",
    "        response=requests.patch(roomlink,  headers={\n",
    "               'Authorization': user_data['token']})\n",
    "#         print(roomlink)\n",
    "#         print(response.json()['success'])\n",
    "        # session ID matches, redirect to another page   \n",
    "        return render_template('meeting_room.html')\n",
    "    else:\n",
    "        print(\"False Info\")\n",
    "        # session ID doesn't match, display error message\n",
    "        return render_template('join_meeting.html', error='Session ID is incorrect')\n",
    "        #return render_template('join_meeting.html')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/run_eye_tracking')\n",
    "def run_eye_tracking(video_frames):\n",
    "    def play_alarm():\n",
    "        #time.sleep(3)\n",
    "        frequency = 3500  # Set Frequency To 2500 Hertz\n",
    "        duration = 5000  # Set Duration To 1000 ms == 1 second\n",
    "        winsound.Beep(frequency, duration)\n",
    "   \n",
    "\n",
    "    # Define a function to calculate the eye aspect ratio\n",
    "    def eye_aspect_ratio(eye):\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "\n",
    "\n",
    "    \n",
    "    # Initialize dlib's face detector and create a dictionary to map facial landmark indexes to face parts\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    face_parts = face_utils.FACIAL_LANDMARKS_IDXS\n",
    "    (left_eye_start, left_eye_end) = face_parts[\"left_eye\"]\n",
    "    (right_eye_start, right_eye_end) = face_parts[\"right_eye\"]\n",
    "\n",
    "    # Start the video stream and wait for the camera to warm up\n",
    "    with open('video.mp4', 'wb') as f:\n",
    "        f.write(base64.b64decode(video_frames))\n",
    "        \n",
    "    video_path = os.path.join('videos', 'video.mp4')\n",
    "        \n",
    "    vs = video_path\n",
    "#     time.sleep(2.0)\n",
    "\n",
    "    # Initialize variables for calculating the attention level\n",
    "    drowsy_counter = 0\n",
    "    drowsy_threshold = 15\n",
    "    focused_counter = 0\n",
    "    focused_threshold = 5\n",
    "    unfocused_counter = 0\n",
    "    unfocused_threshold = 20\n",
    "    max_attention_level = \"unfocused\"\n",
    "    max_attention_time = time.time()\n",
    "    \n",
    "    eyes_closed = False\n",
    "\n",
    "    # Loop over frames from the video stream\n",
    "    while True:\n",
    "        ret, frame = vs.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Resize the frame\n",
    "        frame = imutils.resize(frame, width=800)\n",
    "        \n",
    "        \n",
    "    \n",
    "        # Convert the frame to grayscale and detect faces\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "    \n",
    "        # Reset the eye positions\n",
    "        left_eye_position = None\n",
    "        right_eye_position = None\n",
    "\n",
    "        # Loop over the face detections\n",
    "        for rect in rects:\n",
    "            # Determine the facial landmarks for the face region, then convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "            # Extract the left and right eye coordinates and compute the eye aspect ratio for each eye\n",
    "            left_eye = shape[left_eye_start:left_eye_end]\n",
    "            right_eye = shape[right_eye_start:right_eye_end]\n",
    "            left_eye_ear = eye_aspect_ratio(left_eye)\n",
    "            right_eye_ear = eye_aspect_ratio(right_eye)\n",
    "\n",
    "            # Compute the average eye aspect ratio\n",
    "            avg_ear = (left_eye_ear + right_eye_ear) / 2.0\n",
    "    \n",
    "            # Check if the average eye aspect ratio is below the drowsy threshold\n",
    "            if avg_ear < 0.25:\n",
    "                drowsy_counter += 1\n",
    "                focused_counter = 0\n",
    "                unfocused_counter = 0\n",
    "            else:\n",
    "                drowsy_counter = 0\n",
    "                focused_counter += 1\n",
    "                # Check if eyes are not in the frame\n",
    "                if left_eye.shape[0] == 0 or right_eye.shape[0] == 0:\n",
    "                    unfocused_counter += 1\n",
    "                else:\n",
    "                    left_eye_position = left_eye\n",
    "                    right_eye_position = right_eye\n",
    "\n",
    "            # Check if the attention level is drowsy\n",
    "            if drowsy_counter >= drowsy_threshold:\n",
    "                max_attention_level = \"drowsy\"\n",
    "                if drowsy_counter == drowsy_threshold:\n",
    "                    alarm_start_time = time.time()\n",
    "                if time.time() - alarm_start_time >= 3 and not eyes_closed:\n",
    "                    play_alarm()\n",
    "                    #eyes_closed = True\n",
    "                    drowsy_counter = 0\n",
    "            \n",
    "            # Check if the attention level is unfocused\n",
    "            if unfocused_counter >= unfocused_threshold:\n",
    "                max_attention_level = \"unattentive\"\n",
    "\n",
    "            # Check if the attention level is focused\n",
    "            if focused_counter >= focused_threshold:\n",
    "                max_attention_level = \"focused\"\n",
    "\n",
    "\t  \n",
    "\n",
    "     # Update the max attention level\n",
    "        if time.time() - max_attention_time >= 10:\n",
    "            print(f\"Max attention level for the past 10 Seconds : {max_attention_level}\")\n",
    "            #generate_heatmap(max_attention_level)\n",
    "            max_attention_level = \"unattentive\"\n",
    "            max_attention_time = time.time()\n",
    "\n",
    "        # Display the frame\n",
    "#         cv2.imshow(\"Student Attention Dettection\", frame)\n",
    "#         key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # If the `q` key was pressed, break from the loop\n",
    "#         if key == ord(\"q\"):\n",
    "#             break\n",
    "\n",
    "    # Cleanupq\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# @app.route('/video_feed')\n",
    "# def video_feed():\n",
    "#     return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "    \n",
    "def generate_heatmap(attention_level):\n",
    "    global heatmap\n",
    "    color_map = {\"focused\": (0, 255, 0), \"unfocused\": (0, 0, 255), \"drowsy\": (255, 0, 0), \"unattentive\": (255, 255, 0)}\n",
    "\n",
    "    color = color_map[attention_level]\n",
    "    center_pixel = (heatmap.shape[1] // 2, heatmap.shape[0] // 2)\n",
    "\n",
    "    heatmap[center_pixel] = tuple(color)\n",
    "    print(heatmap)\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b2490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
